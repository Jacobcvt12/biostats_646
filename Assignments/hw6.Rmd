---
title: "Homework 6"
author: "Jacob Carey"
date: \today
header-includes:
    - \usepackage{amsthm}
    - \usepackage{mathtools}
    - \usepackage{dsfont}
output: pdf_document
---

```{r, echo=FALSE}
knitr::opts_chunk$set(message=FALSE)
```

1. 
    (a) The number of possible combinations is
        $$
        \begin{aligned}
        {2n \choose 2} \times {2n-2 \choose 2} \times \dotsm \times {2n - (2n-2) \choose 2} &= \frac{(2n)!}{2!(2n-2)!} \times \dotsm \times 
        \frac{(2n-(2n-2))!}{2!(2n-(2n-2)-2)!} \\
        &= \frac{2n(2n-1)}{2!} \times \dotsm \times \frac{2\times 1}{2!} \\
        &= \frac{(2n)!}{2^n}
        \end{aligned}
        $$
        At step 1, we have $n$ options for choosing a matching long and short pair, at step 2, we have $n-1$ options for choosing a matching pair, etc. Thus the probability that the parts will be joined in the original order is
        $$
        \boxed{n! \times \frac{2^n}{(2n)!}}
        $$

    (b) The number of possible combinations is the same as part (a). However, at step 1, we have $n^2$ possibilities for choices, step 2 we have $(n-1)^2$, etc. Across all $n$ pairs, we have $(n!)^2$.

        Thus, our probability of matching all long parts to short parts is 
        $$
        \frac{2^n(n!)^2}{(2n)!} = \boxed{\frac{2^n}{{2n \choose n}}}
        $$

2. 
    $$ 
    \begin{aligned}
    \int_{x^2 > 0} x^2 f(x) dx &= \int_0^{\infty} x^2 f(x) dx \\
    &= \int_0^{\infty}\{\int_0^{x^2}du\}f_X(x) dx \text{ where $u=x^2$} \\
    &= \int_0^{\infty} \{\int_u^{\infty} f_X(x)dx\}du \\
    &= \int_0^{\infty} 1 - F_X(u) du \\
    &= \boxed{\int_0^{\infty} 2x [1-F_X(x)] dx}
    \end{aligned}
    $$

3.
    $$ 
    P_X(z) = \sum_{x=0}^{n-1} z^x f_X(x) = \sum_0^{n-1}z^x\frac{1}{n}
    =\frac{1}{n}\sum_0^{n-1}z^x = \boxed{\frac{1}{n}\times
    \frac{z^n-1}{z-1}}
    $$

4. We show that $\mathds{1}_{A \cup B}=\mathds{1}_A + \mathds{1}_B - \mathds{1}_A\mathds{1}_B$.  

    Let $\omega \in A \cup B$. Then  
        (1) $\mathds{1}_{A\cup B} = 1$  
        (2) $\omega \in A, \omega \in B$, or $\omega \notin A, \omega \in B$, $\omega \in A, \omega \notin B$. Note that the second and third possibilities are equivalent  
        (3) a. $\omega \in A, \omega \in B \implies \mathds{1}_A = 1,  \mathds{1}_B=1, \mathds{1}_A\mathds{1}_B= 1$  
            b. $\omega \notin A, \omega \in B \implies \mathds{1}_A = 0,  \mathds{1}_B=1, \mathds{1}_A\mathds{1}_B= 0$  
        (4) $\mathds{1}_A +  \mathds{1}_B -  \mathds{1}_A\mathds{1}_B=1$  

    Let $\omega \notin A \cup B$. Then  
        (1) $\mathds{1}_{A\cup B} = 0$  
        (2) $\omega \notin A, \omega \notin B \implies \mathds{1}_A = 0,  \mathds{1}_B=0$  
        (3) $\mathds{1}_A \mathds{1}_B = 0$  
        (4) $\mathds{1}_A + \mathds{1}_B - \mathds{1}_A\mathds{1}_B=0$  

    Next, we show that $\mathds{1}_A \mathds{1}_B = \mathds{1}_{A\cap B}$

    Let $\omega \in A \cap B$. Then  
        (1) $\mathds{1}_{A\cap B} = 1$  
        (2) $\omega \in A, \omega \in B \implies \mathds{1}_A = 1,  \mathds{1}_B=1$  
        (3) $\mathds{1}_A \mathds{1}_B = 1$  

    Let $\omega \notin A \cap B$. Then  
        (1) $\mathds{1}_{A\cap B} = 0$  
        (2) Either $\omega \in A, \omega \notin B$ $\omega \notin A, \omega \in B$, or $\omega \notin A, \omega \notin B$. WLOG, suppose or $\omega \in A, \omega \notin B \implies \mathds{1}_A = 1,  \mathds{1}_B=0$  
        (3) $\mathds{1}_A \mathds{1}_B = 0$  

    Finally, we use these identities to show the proof.

    $$
    P(A\cup B) = E(\mathds{1}_{A\cup B}) = E(\mathds{1}_A + \mathds{1}_B - \mathds{1}_A \mathds{1}_B) = 
    E(\mathds{1}_A) + E(\mathds{1}_B) - E(\mathds{1}_{A\cap B}) =
    P(A) + P(B) - P(A\cap B) \qedsymbol
    $$

5.
    (a) 
        $$
        \frac{d}{dt} H(t) = -\frac{d}{dt} \log(1-F(t)) =
        \boxed{\frac{f(t)}{1-F(t)}}
        $$

    (b) By definition, $P(X>t)=1-F(t)$. Then we just need to show that 
    $$\lim_{h \downarrow 0} \frac{P(X\leq t+h)}{h} = f(t)$$
    Then 
    $$P(X\leq t+h)/h = \frac{P(t\leq X\leq h | X > t)}{h}$$
    The limit of this is the definition of a density function and so
    $$\lim_{h \downarrow 0} \frac{P(X\leq t+h)}{h} = f(t)$$

    (c)
    $$
    \begin{aligned}
    P(X>t+s|X>t) &= \frac{P(X>t+s, X>t)}{P(X>t)} \\
    &= \frac{P(X>t+s)}{P(X>t)} \\
    &= \frac{1-F(t+s)}{1-F(t)} \\
    &= \exp(-(-\log(1-F(t))+\log(1-F(t)))) \\
    &= -(H(t+s)-H(t)) \\
    &= \int_t^{t+s}h(u) du
    \end{aligned}
    $$

6. 
    (a)
    ```{r}
    library(ggplot2)
    library(dplyr)

    dlaplace <- function(x, lambda=1) lambda / 2 * exp(-lambda * abs(x))

    x <- seq(-10, 10, by=0.1)

    data <- bind_rows(data_frame(x=x, 
                                 density=dlaplace(x, lambda=1),
                                 lambda=1),
                      data_frame(x=x, 
                                 density=dlaplace(x, lambda=4),
                                 lambda=4),
                      data_frame(x=x, 
                                 density=dlaplace(x, lambda=6),
                                 lambda=6)) %>%
        mutate(lambda=as.character(lambda))

    ggplot(data, aes(x=x, y=density)) +
        geom_line(aes(colour=lambda, linetype=lambda)) +
        theme_classic()
    ```
    (b)
    $$
    \begin{aligned}
    M_X(t) &= E[e^{tx}] \\
    &= \int_{-\infty}^{\infty} e^{tx} f(x) dx \\
    &= \int_{-\infty}^{\infty} e^{tx} \frac{\lambda}{2}e^{-\lambda
    |x|} dx \\
    &= \frac{\lambda}{2} \int_{-\infty}^{0} e^{x(t+\lambda)} dx  + 
    \frac{\lambda}{2} \int_{0}^{\infty} e^{x(t-\lambda)} \\
    &= -\frac{\lambda^2}{(t+\lambda)(t-\lambda)}
    \end{aligned}
    $$

    (c) 
    $$
    \frac{\partial}{\partial t} M_x(t) =
    \frac{2t\lambda^2}{(t-\lambda)^2(t+\lambda)^2} \implies
    \text{Mean}=0
    $$
    $$
    \frac{\partial^2}{\partial t^2} M_x(t) =
    \frac{2\lambda^2(3t^2+\lambda^2)}{(\lambda-t)^3(t+\lambda)^3} \implies
    \text{Variance}=\frac{2}{\lambda^2}
    $$
    (d) For $z \leq 0$
    $$
    F_{Z=X-Y}=\int_0^{\infty} \int_{x-z}^{\infty} e^{-x}e^{-y}dy dx =
    \frac{e^z}{2}
    $$
    For $z > 0$
    $$
    F_{Z=X-Y}=\int_z^{\infty} \int_{0}^{x-z} e^{-x}e^{-y}dy dx =
    1-\frac{e^{-z}}{2}
    $$
    Then $f_Z=\frac{e^{-z}}{2}$ which is a Laplace$(\lambda=1)$
    (e)
    From before, we have that $E[X]=0$ and Var $X=\frac{2}{\lambda^2}$.
    Then
    $$
    \begin{aligned}
    \text{MGF}_{W_n}(t) &= E[\exp(\frac{t \lambda}{\sqrt{2n}} \bar{X})] \\
    &= E[\exp(t\lambda/\sqrt{2n} \sum X_i)] \\
    &= \Pi \text{MGF}_{X_i} (t \lambda/\sqrt{2n}) \\
    &= \Big(\frac{-\lambda^2}{\frac{t^2\lambda^2}{2n}-\lambda^2}\Big)^n \\
    &= \frac{1}{(1-\frac{t^2}{2n})^n}
    \end{aligned}
    $$
    (f)
    The limiting MGF is $\exp(\frac{-t^2}{2})$
    (g)
    This is the MGF of a normal distribution with mean 0 and variance 1.
